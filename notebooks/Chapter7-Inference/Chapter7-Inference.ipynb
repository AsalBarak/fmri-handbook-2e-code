{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import os,sys,shutil\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import nilearn.plotting\n",
    "%matplotlib inline\n",
    "import nibabel\n",
    "from nipype.interfaces import fsl\n",
    "from nipy.modalities.fmri.hemodynamic_models import spm_hrf,compute_regressor\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "from __future__ import division\n",
    "\n",
    "from nipype.caching import Memory\n",
    "# use nipype's caching mechanism to save the results of the processing\n",
    "mem = Memory(base_dir='.')\n",
    "\n",
    "# set up rpy2 so we can use R magic\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "from fmrihandbook.utils.config import Config\n",
    "from fmrihandbook.utils.show_image import showPDF\n",
    "\n",
    "config=Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 7.1__: Use manually generated original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://web.stanford.edu/group/poldracklab/fmri-handbook-2e-data/figures-1e/Figure_7_1.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"319\"\n",
       "            height=\"272\"\n",
       "            src=\"https://web.stanford.edu/group/poldracklab/fmri-handbook-2e-data/figures-1e/Figure_7_1.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x101c32588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showPDF(os.path.join(config.orig_figuredir,'Figure_7_1.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 7.2:__ Effects of cluster-forming threshold on cluster size. The same data were thresholded using increasing cluster-size thresholds; the resulting clusters are randomly color-coded to show which voxels belong to each cluster. At the lowest threshold, there is one large cluster that encompasses much of the brain, whereas higher thresholds break up this cluster, at the expense of excluding many regions that do not survive the higher threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://web.stanford.edu/group/poldracklab/fmri-handbook-2e-data/figures-1e/Figure_7_2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"624\"\n",
       "            height=\"242\"\n",
       "            src=\"https://web.stanford.edu/group/poldracklab/fmri-handbook-2e-data/figures-1e/Figure_7_2.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1040f39b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showPDF(os.path.join(config.orig_figuredir,'Figure_7_2.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datadir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cc3c2d507a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# using FSL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstudydir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds009'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcopefile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudydir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'task002_cope002_succstop.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvarcopefile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudydir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'task002_varcope002_succstop.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datadir' is not defined"
     ]
    }
   ],
   "source": [
    "# first need to run group analysis on ds009 dataset\n",
    "# using FSL\n",
    "\n",
    "copefile=os.path.join(config.data['ds009']['datadir'],'task002_cope002_succstop.nii.gz')\n",
    "varcopefile=os.path.join(studydir,'task002_varcope002_succstop.nii.gz')\n",
    "nsubs=24\n",
    "deshdr=\"\"\"/NumWaves\t1\n",
    "/NumPoints\t24\n",
    "/PPheights\t\t1.000000e+00\n",
    "\n",
    "/Matrix\"\"\"\n",
    "\n",
    "conhdr=\"\"\"/ContrastName1\tgroup mean\n",
    "/NumWaves\t1\n",
    "/NumContrasts\t1\n",
    "/PPheights\t\t1.000000e+00\n",
    "/RequiredEffect\t\t1.441\n",
    "\n",
    "/Matrix\"\"\"\n",
    "\n",
    "grouphdr=\"\"\"/NumWaves\t1\n",
    "/NumPoints\t24\n",
    "\n",
    "/Matrix\"\"\"\n",
    "desmtx=numpy.ones((nsubs,1))\n",
    "numpy.savetxt('design.mat',desmtx,fmt='%1.0f',header=deshdr,comments='')\n",
    "numpy.savetxt('covsplit.txt',desmtx,fmt='%1.0f',header=grouphdr,comments='')\n",
    "conmtx=numpy.ones(1)\n",
    "numpy.savetxt('design.con',conmtx,fmt='%1.0f',header=conhdr,comments='')\n",
    "\n",
    "if not os.path.exists(os.path.join(studydir,'stats_OLS')):\n",
    "    level2=mem.cache(fsl.FLAMEO)\n",
    "    flameo_results = level2(cope_file=copefile, \n",
    "                        var_cope_file=varcopefile,\n",
    "                        design_file='design.mat',\n",
    "                        cov_split_file='covsplit.txt',\n",
    "                        t_con_file='design.con',\n",
    "                        mask_file=os.path.join(os.getenv('FSLDIR'),'data/standard/MNI152_T1_2mm_brain_mask_dil.nii.gz'),\n",
    "                        run_mode='ols')\n",
    "\n",
    "    flameo_results.outputs\n",
    "\n",
    "    shutil.move(flameo_results.outputs.stats_dir,os.path.join(studydir,'stats_OLS'))\n",
    "\n",
    "\n",
    "est = mem.cache(fsl.SmoothEstimate)\n",
    "smoothness=est(dof=23,\n",
    "    residual_fit_file = os.path.join(studydir,'stats_OLS/res4d.nii.gz'),\n",
    "    mask_file = os.path.join(os.getenv('FSLDIR'),'data/standard/MNI152_T1_2mm_brain_mask_dil.nii.gz'))\n",
    "\n",
    "print(smoothness.outputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create outputs for different thresholds\n",
    "cl = mem.cache(fsl.Cluster)\n",
    "cluster_results={}\n",
    "\n",
    "bgimage=nibabel.load(os.path.join(os.getenv('FSLDIR'),'data/standard/MNI152_T1_2mm_brain.nii.gz'))\n",
    "\n",
    "for thresh in [2,3,4,5]:\n",
    "    cluster_results[thresh]=cl(threshold = thresh,\n",
    "       in_file = os.path.join(studydir,'stats_OLS/zstat1.nii.gz'),\n",
    "        dlh=smoothness.outputs.dlh,\n",
    "        volume=smoothness.outputs.volume,\n",
    "        pthreshold=0.05,\n",
    "        out_localmax_txt_file=os.path.join(studydir,'stats_OLS/zstat1_cluster_localmax_thresh%d.txt'%thresh),\n",
    "        out_index_file=os.path.join(studydir,'stats_OLS/zstat1_cluster_index_thresh%d.nii.gz'%thresh),\n",
    "        out_threshold_file=os.path.join(studydir,'stats_OLS/zstat1_thresh_thresh%d.nii.gz'%thresh))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "for thresh in [2,3,4,5]:\n",
    "    idxdata=nibabel.load(os.path.join(studydir,'stats_OLS/zstat1_cluster_index_thresh%d.nii.gz'%thresh)).get_data()\n",
    "    nvox=numpy.sum(idxdata==numpy.max(idxdata))\n",
    "    nclust=len(numpy.unique(idxdata))\n",
    "    print thresh,nvox\n",
    "    ax1 = plt.subplot2grid((2,4), (0,thresh-2))\n",
    "    plot=nilearn.plotting.plot_stat_map(os.path.join(studydir,'stats_OLS/zstat1_thresh_thresh%d.nii.gz'%thresh),\n",
    "                        bgimage,threshold=thresh,\n",
    "                        display_mode='z',cut_coords=[0],axes=ax1,\n",
    "                        annotate=False,colorbar=False)\n",
    "    xlim=plot.axes[0.0].ax.get_xlim()\n",
    "    ylim=plot.axes[0.0].ax.get_ylim()\n",
    "    \n",
    "    plt.text(numpy.mean(xlim),ylim[1]+45,'Z > %d'%thresh,fontsize=18,horizontalalignment='center')\n",
    "    plt.text(numpy.mean(xlim),ylim[0]-55,'%d clusters'%nclust,fontsize=18,horizontalalignment='center')\n",
    "    plt.text(numpy.mean(xlim),ylim[0]-75,'largest: %d voxels'%nvox,fontsize=14,horizontalalignment='center')\n",
    "\n",
    "plt.savefig(os.path.join(config.figuredir,'Figure_7_2.'+config.img_format),format=config.img_format,dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 7.3__: Use manually generated original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showPDF(os.path.join(config.orig_figuredir,'Figure_7_3.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 7.4:__ Illustration of three different multiple comparison procedures. Each column corresponds to a different realization of signal plus noise as illustrated in the simulated data in the top row, and can be thought of as your next ten experiments. The top row shows the statistic image without any thresholding. The second row illustrates the control of the per comparison rate at 10%, that is, no special account of multiplicity. The third row shows control of the familywise error rate at 10%, say with RFT or Bonferroni. The bottom row shows control of the false discovery rate. With no adjustment for multiple testing (second row) there is excellent sensitivity, but very poor specificity – there are false positives everywhere. Controlling FWE (third row) gives excellent specificity – only 1 out of 10 experiments have any false positives— but poor sensitivity. Controlling FDR (bottom row) is a compromise between no correction and FWE correction, giving greater sensitivity at the expense of some false positives, even though it is still controlled as a fraction of all voxels detected. Note that, just as the emperical per comparison error rate for each experiment is never exactly 10%, likewise the emperical false discovery rate is never exactly 10%; in both instances, we’re guaranteed only that, in the long run, the average rate will not exceed 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showPDF(os.path.join(config.orig_figuredir,'Figure_7_4.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "# first generate 10 realizations of data\n",
    "\n",
    "# fix seed to an example that gives one FWE\n",
    "seed=95302\n",
    "numpy.random.seed(seed) \n",
    "\n",
    "nsubs=24\n",
    "img=numpy.zeros((100,100,nsubs)) \n",
    "baseimg=numpy.zeros((100,100))\n",
    "baseimg[35:65,35:65]=1\n",
    "\n",
    "for i in range(nsubs):\n",
    "    img[:,:,i]=baseimg\n",
    "onvox=numpy.where(baseimg==1)\n",
    "offvox=numpy.where(baseimg==0)\n",
    "\n",
    "images={}\n",
    "tstat={}\n",
    "pvals={}\n",
    "noise_sd=1\n",
    "pval=0.1\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "for i in range(10):\n",
    "    data=img+numpy.random.randn(100,100,nsubs)*noise_sd\n",
    "    images[i]=numpy.mean(data,2)\n",
    "    t=scipy.stats.ttest_1samp(data,0,axis=2)\n",
    "    tstat[i]=t.statistic\n",
    "    pvals[i]=t.pvalue\n",
    "    \n",
    "    # plot raw values\n",
    "    ax1 = plt.subplot2grid((4,10), (0,i))\n",
    "    plot=plt.imshow(tstat[i],cmap='gray',vmin=-3,vmax=3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    xlim=plot.axes.get_xlim()\n",
    "    ylim=plot.axes.get_ylim()\n",
    "    if i==4:\n",
    "        plt.text(numpy.mean(xlim)-40,ylim[1]-10,'Signal + noise',\n",
    "                fontsize=18)\n",
    "        \n",
    "    # plot uncorrected\n",
    "    ax1 = plt.subplot2grid((4,10), (1,i))\n",
    "    thresh_p=pvals[i]<pval\n",
    "    plot=plt.imshow(thresh_p,cmap='gray',vmin=0,vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    xlim=plot.axes.get_xlim()\n",
    "    ylim=plot.axes.get_ylim()\n",
    "    plt.text(numpy.mean(xlim),ylim[0]+20,'%0.2f'%float(numpy.mean(thresh_p[offvox])),\n",
    "             horizontalalignment='center')\n",
    "    if i==4:\n",
    "        plt.text(numpy.mean(xlim)-170,ylim[1]-10,'Control of per comparison rate at 10%',\n",
    "                fontsize=18)\n",
    "        plt.text(numpy.mean(xlim)-180,ylim[0]+40,'Percentage of null pixels that are false positives',\n",
    "                fontsize=14)\n",
    "    \n",
    "    # plot bonferroni control\n",
    "    ax1 = plt.subplot2grid((4,10), (2,i))\n",
    "    pval_array=pvals[i].ravel()\n",
    "    _,corr_p,_,_=multipletests(pval_array,pval,'bonferroni')\n",
    "    corr_p=corr_p.reshape(pvals[i].shape)\n",
    "    sig=corr_p<pval\n",
    "    #corr_p=pvals[i]*numpy.prod(pvals[i].shape)\n",
    "    plot=plt.imshow(numpy.array(corr_p<pval).astype('int'),cmap='gray',vmin=0,vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    xlim=plot.axes.get_xlim()\n",
    "    ylim=plot.axes.get_ylim()\n",
    "    if numpy.sum(sig[offvox])>0:\n",
    "        plt.text(numpy.mean(xlim),ylim[0]+20,'FWE',\n",
    "             horizontalalignment='center')\n",
    "    if i==4:\n",
    "        plt.text(numpy.mean(xlim)-180,ylim[1]-10,'Control of familywise error rate at 10%',\n",
    "                fontsize=18)\n",
    "        plt.text(numpy.mean(xlim)-100,ylim[0]+40,'Occurrence of familywise error',\n",
    "                fontsize=14)\n",
    "    \n",
    "    # FDR control\n",
    "    ax1 = plt.subplot2grid((4,10), (3,i))\n",
    "    pval_array=pvals[i].ravel()\n",
    "    _,corr_p,_,_=multipletests(pval_array,pval,'fdr_bh')\n",
    "    corr_p=corr_p.reshape(pvals[i].shape)\n",
    "    sig=corr_p<pval\n",
    "    #corr_p=pvals[i]*numpy.prod(pvals[i].shape)\n",
    "    plot=plt.imshow(numpy.array(corr_p<pval).astype('int'),cmap='gray',vmin=0,vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    xlim=plot.axes.get_xlim()\n",
    "    ylim=plot.axes.get_ylim()\n",
    "    fdr_obs=numpy.sum(sig[offvox])/numpy.sum(sig)\n",
    "    plt.text(numpy.mean(xlim),ylim[0]+20,'%0.2f'%fdr_obs,\n",
    "             horizontalalignment='center')\n",
    "    if i==4:\n",
    "        plt.text(numpy.mean(xlim)-170,ylim[1]-10,'Control of false discovery rate at 10%',\n",
    "                fontsize=18)\n",
    "        plt.text(numpy.mean(xlim)-180,ylim[0]+40,'Percentage of active pixels that are false positives',\n",
    "                fontsize=14)\n",
    "\n",
    "plt.savefig(os.path.join(config.figuredir,'Figure_7_4.'+config.img_format),format=config.img_format,dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 7.5:__ Thresholded maps from the gambling experiment, parametric effect of the size of potential loss on BOLD response. Top (a) shows clusters created with Z = 2.3 cluster-forming threshold and no cluster-size threshold, while bottom (b) shows the 3 clusters that survive a critical cluster size threshold of 570 voxels.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showPDF(os.path.join(config.orig_figuredir,'Figure_7_5.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zstat_cope3=nibabel.load(os.path.join(datadir,'ds005/ds005_cope3_zstat2.nii.gz'))\n",
    "bgimage=nibabel.load(os.path.join(os.getenv('FSLDIR'),'data/standard/MNI152_T1_2mm_brain.nii.gz'))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax1 = plt.subplot2grid((2,1), (0,0))\n",
    "plot=nilearn.plotting.plot_stat_map(zstat_cope3,\n",
    "                        bgimage,threshold=2.3,\n",
    "                        display_mode='ortho',axes=ax1,\n",
    "                        annotate=False,colorbar=False)\n",
    "xlim=plot.axes['y'].ax.get_xlim()\n",
    "ylim=plot.axes['y'].ax.get_ylim()\n",
    "plt.text(numpy.mean(xlim)-240,ylim[1]+15,'Gambling task - all 154 clusters',\n",
    "                fontsize=14)\n",
    "# perform clustering\n",
    "cl = mem.cache(fsl.Cluster)\n",
    "clustidx=os.path.join(datadir,'ds005/ds005_cope3_zstat2_clustidx.nii.gz')\n",
    "if not os.path.exists(clustidx):\n",
    "    cluster_results=cl(threshold = 2.3,\n",
    "        in_file = os.path.join(datadir,'ds005/ds005_cope3_zstat2.nii.gz'),\n",
    "        out_index_file=clustidx)\n",
    "clustimg=nibabel.load(clustidx)\n",
    "clustdata=clustimg.get_data()\n",
    "\n",
    "nclust=numpy.max(clustdata)\n",
    "extent_thresh=570\n",
    "for i in range(1,nclust+1):\n",
    "    if numpy.sum(clustdata==i)<extent_thresh:\n",
    "        clustdata[clustdata==i]=0\n",
    "clustdata[clustdata>0]=1\n",
    "\n",
    "zstatdata=nibabel.load(os.path.join(datadir,'ds005/ds005_cope3_zstat2.nii.gz')).get_data()\n",
    "clust_extent_thresh=nibabel.Nifti1Image(clustdata*zstatdata,clustimg.get_affine(),clustimg.get_header())\n",
    "clust_extent_thresh.to_filename(os.path.join(datadir,\n",
    "                        'ds005/ds005_cope3_zstat2_extentthresh.nii.gz'))\n",
    "\n",
    "ax1 = plt.subplot2grid((2,1), (1,0))\n",
    "plot=nilearn.plotting.plot_stat_map(clust_extent_thresh,\n",
    "                        bgimage,threshold=2.3,\n",
    "                        display_mode='ortho',axes=ax1,\n",
    "                        annotate=False,colorbar=False)\n",
    "xlim=plot.axes['y'].ax.get_xlim()\n",
    "ylim=plot.axes['y'].ax.get_ylim()\n",
    "plt.text(numpy.mean(xlim)-300,ylim[1]+15,'Gambling task - clusters surviving 5% FWE threshold',\n",
    "                fontsize=14)\n",
    "plt.savefig(os.path.join(config.figuredir,'Figure_7_5.'+config.img_format),format=config.img_format,dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 7.6:__ Use original manaully generated art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showPDF(os.path.join(config.orig_figuredir,'Figure_7_6.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 7.7:__ Power curve. The curve was generated using an estimated mean effect of 0.8% signal change units with standard deviation of 2% signal change units and a type I error rate of 0.05 using Equation 7.2. Since the graph crosses 80% between 40 and 41 subjects, a sample size of 41 will yield at least 80% power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showPDF(os.path.join(config.orig_figuredir,'Figure_7_7.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu=0.8\n",
    "sigma=2.0\n",
    "alpha=0.05\n",
    "N=41\n",
    "\n",
    "def power(mu,sigma,N):\n",
    "    ncp=(numpy.sqrt(N)*mu)/sigma\n",
    "    nct= scipy.stats.nct(N-1, ncp)\n",
    "    t=scipy.stats.t.ppf(1-alpha,N-1)\n",
    "    return 1 - nct.cdf(t)\n",
    "\n",
    "nvals=range(10,50)\n",
    "p=numpy.zeros(len(nvals))\n",
    "for i in range(len(nvals)):\n",
    "    p[i]=power(mu,sigma,nvals[i])\n",
    "    \n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(nvals,p)\n",
    "plt.plot([numpy.min(nvals),numpy.max(nvals)],[0.8,0.8],color='red',linestyle='--')\n",
    "plt.xlabel('Sample size',fontsize=18)\n",
    "plt.ylabel('Power (%)',fontsize=18)\n",
    "plt.savefig(os.path.join(config.figuredir,'Figure_7_7.'+config.img_format),format=config.img_format,dpi=1200)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
